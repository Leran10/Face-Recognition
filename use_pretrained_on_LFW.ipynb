{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kewu/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 125, 125, 3)\n",
      "(93,)\n",
      "(25, 125, 125, 3)\n",
      "(25,)\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# load training and test data\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import cv2 as cv\n",
    "\n",
    "# resize input data to be 125*125\n",
    "size = (125, 125)\n",
    "\n",
    "data_train = pickle.load(open(\"data/image_data_train224.pkl\",\"rb\"))\n",
    "data_test = pickle.load(open(\"data/image_data_test224.pkl\",\"rb\"))\n",
    "class_list = pickle.load(open(\"data/class_list.pkl\", \"rb\"))\n",
    "\n",
    "# the data structure in image_data_train224.pkl\n",
    "# it is a list of (image, label) tuple, each image is a matrix of (224, 224, 3)\n",
    "\n",
    "X_train = np.array([cv.resize(x[0], size)/255. for x in data_train])\n",
    "X_test = np.array([cv.resize(x[0], size)/255. for x in data_test])\n",
    "\n",
    "Y_train = np.array([x[1] for x in data_train])\n",
    "Y_test = np.array([x[1] for x in data_test])\n",
    "\n",
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "print X_test.shape\n",
    "print Y_test.shape\n",
    "print X_train.max()\n",
    "print X_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join('saved_models')\n",
    "model_name1 = 'keras_lfw_trained_model.h5'\n",
    "model_name2 = 'keras_lfw_trained_model_150_mobileNet.h5'\n",
    "\n",
    "# model 1, simple model, part of VGG, accuracy on LFW: 0.51, training hours: 10h\n",
    "# model 2, mobileNet, accuracy on LFW: 0.64, training hours: 14h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model_path = os.path.join(save_dir, model_name1)\n",
    "model_simple = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 125, 125, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 125, 125, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 123, 123, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 123, 123, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 59, 59, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               27558400  \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 158)               81054     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 158)               0         \n",
      "=================================================================\n",
      "Total params: 27,705,022\n",
      "Trainable params: 27,705,022\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_17\n",
      "activation_25\n",
      "conv2d_18\n",
      "activation_26\n",
      "max_pooling2d_9\n",
      "dropout_13\n",
      "conv2d_19\n",
      "activation_27\n",
      "conv2d_20\n",
      "activation_28\n",
      "max_pooling2d_10\n",
      "dropout_14\n",
      "flatten_5\n",
      "dense_9\n",
      "activation_29\n",
      "dropout_15\n",
      "dense_10\n",
      "activation_30\n"
     ]
    }
   ],
   "source": [
    "for l in model_simple.layers:\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "layer_name = 'activation_29'\n",
    "get_embedding_layer_output = K.function([model_simple.layers[0].input, K.learning_phase()],[model_simple.get_layer(layer_name).output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "x = np.random.rand(1,125,125,3)\n",
    "layer_output_test = get_embedding_layer_output([x, 0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.      , 0.      , 0.      , 0.      , 0.      , 0.      ,\n",
       "       0.      , 4.329412, 0.      , 0.      ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output_test[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 512)\n",
      "(25, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH2wE+mGiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141bdd050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_embedding = get_embedding_layer_output([X_train, 0])[0]\n",
    "X_test_embedding = get_embedding_layer_output([X_test, 0])[0]\n",
    "\n",
    "print X_train_embedding.shape\n",
    "print X_test_embedding.shape\n",
    "\n",
    "plt.hist(X_train_embedding.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  1.0\n",
      "test accuracy:  0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "# it is identical to only optimize over the top layer\n",
    "# previously the best we can get is 0.72 accuracy\n",
    "\n",
    "model = LR()\n",
    "model.fit(X_train_embedding, Y_train)\n",
    "print \"training accuracy: \", model.score(X_train_embedding, Y_train)\n",
    "print \"test accuracy: \", model.score(X_test_embedding, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 125, 125, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 127, 127, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 63, 63, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, 65, 65, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 63, 63, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 63, 63, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 63, 63, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 63, 63, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 65, 65, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 10, 10, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, 6, 6, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 158)         161950    \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 158)         0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 158)               0         \n",
      "=================================================================\n",
      "Total params: 3,390,814\n",
      "Trainable params: 3,368,926\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "model_path_mobileNet = os.path.join(save_dir, model_name2)\n",
    "model_mobilenet = load_model(model_path_mobileNet, custom_objects={\n",
    "                   'relu6': mobilenet.relu6,\n",
    "                   'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n",
    "\n",
    "print model_mobilenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note:\n",
    "# batch normalization: \n",
    "# To increase the stability of a neural network, batch normalization normalizes the output of a previous \n",
    "# activation layer by subtracting the batch mean and dividing by the batch standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kewu/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"keras_learning_phase:0\", shape=(), dtype=bool)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_mobilenet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5d6018076d37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlayer_name_mobilenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'global_average_pooling2d_1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_embedding_layer_output_mobilenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_mobilenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_mobilenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name_mobilenet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_mobilenet' is not defined"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "print K.learning_phase()\n",
    "layer_name_mobilenet = 'global_average_pooling2d_1'\n",
    "get_embedding_layer_output_mobilenet = K.function([model_mobilenet.layers[0].input, K.learning_phase()],[model_mobilenet.get_layer(layer_name_mobilenet).output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 1024)\n",
      "(25, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngySpYzhIkjqGgySp8//QlJiw5tuftQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123120f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_embedding_mobilenet = get_embedding_layer_output_mobilenet([X_train, 0])[0]\n",
    "X_test_embedding_mobilenet = get_embedding_layer_output_mobilenet([X_test, 0])[0]\n",
    "\n",
    "print X_train_embedding_mobilenet.shape\n",
    "print X_test_embedding_mobilenet.shape\n",
    "\n",
    "plt.hist(X_train_embedding_mobilenet.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  0.6881720430107527\n",
      "test accuracy:  0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "# it is identical to only optimize over the top layer\n",
    "\n",
    "model = LR()\n",
    "model.fit(X_train_embedding_mobilenet, Y_train)\n",
    "print \"training accuracy: \", model.score(X_train_embedding_mobilenet, Y_train)\n",
    "print \"test accuracy: \", model.score(X_test_embedding_mobilenet, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  1.0\n",
      "test accuracy:  0.88\n"
     ]
    }
   ],
   "source": [
    "model = LR()\n",
    "model.fit(X_train.reshape(X_train.shape[0],-1), Y_train)\n",
    "print \"training accuracy: \", model.score(X_train.reshape(X_train.shape[0],-1), Y_train)\n",
    "print \"test accuracy: \", model.score(X_test.reshape(X_test.shape[0],-1), Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion: \n",
    "1. pretraining may help deep network training\n",
    "2. for our case, a noisy pretraining can not beat even logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
